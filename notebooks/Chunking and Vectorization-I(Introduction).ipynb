{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to find the optimized process to \n",
    "- Chunking\n",
    "- Vectorization or Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-1 Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   name                   10000 non-null  object\n",
      " 1   pre-processed_content  10000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('../data/0-10000eng_subtitles.csv',index_col=0).copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pre-processed_content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the.message.(1976).eng.1cd</td>\n",
       "      <td>name god gracious merci muhammad messeng god h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here.comes.the.grump.s01.e09.joltin.jack.in.bo...</td>\n",
       "      <td>ah princess dawn terri blooney looney soldier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd</td>\n",
       "      <td>yumi cell episod extrem polit yumi yumi get ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd</td>\n",
       "      <td>yumi cell episod laptop first place mine mine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>broker.(2022).eng.1cd</td>\n",
       "      <td>go throw away give birth pleas take care anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>recess.(1997).eng.1cd</td>\n",
       "      <td>bell ring children cheer wa umph ah burp right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>recess.(1997).eng.1cd</td>\n",
       "      <td>bell ring children cheer pop ah crash ah burp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>recess.(1997).eng.1cd</td>\n",
       "      <td>bell ring cheer yell whimper org deprec pleas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>recess.(1997).eng.1cd</td>\n",
       "      <td>bell ring children cheer wha use free code joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>recess.(1997).eng.1cd</td>\n",
       "      <td>bell ring children cheer wha ah burp legal ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  \\\n",
       "index                                                      \n",
       "0                             the.message.(1976).eng.1cd   \n",
       "1      here.comes.the.grump.s01.e09.joltin.jack.in.bo...   \n",
       "2        yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd   \n",
       "3        yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd   \n",
       "4                                  broker.(2022).eng.1cd   \n",
       "...                                                  ...   \n",
       "9995                               recess.(1997).eng.1cd   \n",
       "9996                               recess.(1997).eng.1cd   \n",
       "9997                               recess.(1997).eng.1cd   \n",
       "9998                               recess.(1997).eng.1cd   \n",
       "9999                               recess.(1997).eng.1cd   \n",
       "\n",
       "                                   pre-processed_content  \n",
       "index                                                     \n",
       "0      name god gracious merci muhammad messeng god h...  \n",
       "1      ah princess dawn terri blooney looney soldier ...  \n",
       "2      yumi cell episod extrem polit yumi yumi get ma...  \n",
       "3      yumi cell episod laptop first place mine mine ...  \n",
       "4      go throw away give birth pleas take care anyth...  \n",
       "...                                                  ...  \n",
       "9995   bell ring children cheer wa umph ah burp right...  \n",
       "9996   bell ring children cheer pop ah crash ah burp ...  \n",
       "9997   bell ring cheer yell whimper org deprec pleas ...  \n",
       "9998   bell ring children cheer wha use free code joi...  \n",
       "9999   bell ring children cheer wha ah burp legal ten...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step- 2 Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two lists\n",
    "new_id=[]\n",
    "new_content=[]\n",
    "\n",
    "#loop through the dataframe and chunk the content\n",
    "def chunker(chunk_size,id,content):\n",
    "    \n",
    "    tokens=[token for token in content.split()]\n",
    "    #get length of the tokens\n",
    "    n=len(tokens)\n",
    "    \n",
    "    #initialize index and count\n",
    "    index,count=0,0\n",
    "    #print(id,content,tokens)\n",
    "    while True:\n",
    "        if index==0:\n",
    "            si,ei=index,256\n",
    "            if ei>n:\n",
    "                new_id.append(f\"{id}-{count}\")\n",
    "                new_content.append(\" \".join(tokens[si:]))\n",
    "                break\n",
    "            else:\n",
    "                new_id.append(f\"{id}-{count}\")\n",
    "                new_content.append(\" \".join(tokens[si:ei]))\n",
    "                index=ei\n",
    "        else:\n",
    "            si,ei=index-chunk_size,index+256-chunk_size #chunking buffer\n",
    "            if ei>n:\n",
    "                new_id.append(f\"{id}-{count}\")\n",
    "                new_content.append(\" \".join(tokens[si:]))\n",
    "                break\n",
    "            else:\n",
    "                new_id.append(f\"{id}-{count}\")\n",
    "                new_content.append(\" \".join(tokens[si:ei]))\n",
    "                index=ei\n",
    "        count+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    chunker(25,i,df['pre-processed content'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-0</td>\n",
       "      <td>name god gracious merci muhammad messeng god h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-1</td>\n",
       "      <td>poet joy kit love kin wine cake abound skill a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-2</td>\n",
       "      <td>talk tell uncl protect child protect still say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-3</td>\n",
       "      <td>ammar see god kaaba everi day afraid listen pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-4</td>\n",
       "      <td>pleasant idea slave beggar give pretens bilal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>99-9</td>\n",
       "      <td>exeunt flourish work think still reboot need l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>99-10</td>\n",
       "      <td>hey spirit gon na chant name right lay lay rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>99-11</td>\n",
       "      <td>notic lay lay pleas hear real teenag girl avat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>99-12</td>\n",
       "      <td>life best besti anyon could ask hiccup tri alw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>99-13</td>\n",
       "      <td>day work hard everi singl time play caus hater...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                            content\n",
       "0       0-0  name god gracious merci muhammad messeng god h...\n",
       "1       0-1  poet joy kit love kin wine cake abound skill a...\n",
       "2       0-2  talk tell uncl protect child protect still say...\n",
       "3       0-3  ammar see god kaaba everi day afraid listen pe...\n",
       "4       0-4  pleasant idea slave beggar give pretens bilal ...\n",
       "...     ...                                                ...\n",
       "1261   99-9  exeunt flourish work think still reboot need l...\n",
       "1262  99-10  hey spirit gon na chant name right lay lay rea...\n",
       "1263  99-11  notic lay lay pleas hear real teenag girl avat...\n",
       "1264  99-12  life best besti anyon could ask hiccup tri alw...\n",
       "1265  99-13  day work hard everi singl time play caus hater...\n",
       "\n",
       "[1266 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df=pd.DataFrame({'id':new_id,'content':new_content})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name god gracious merci muhammad messeng god heraclius emperor byzantium greet follow righteous guidanc bid hear divin call messeng god peopl accept islam salvat speak new prophet arabia like john baptist came king herod desert cri salvat muqawqi patriarch alexandria kisra emperor persia muhammad call call god accept islam salvat embrac islam come desert smell camel goat tell persia kneel muhammad messeng god gave author god sent muhammad merci mankind scholar historian islam univers al azhar cairo high islam congress shiat lebanon maker film honour islam tradit hold imperson prophet offend spiritu messag therefor person mohammad shown six hundr year christ die europ sunk dark age everywher old civil fall muhammad born mecca arabia mecca rich trade citi rule merchant whose wealth multipli uniqu privileg hous god everi year time great fair desert priest brought idol imag god custodi kaaba holi shrine abraham kaaba becom hous idolotri host fewer three hundr sixti differ god mecca six hundr ten bilal today count umaya yet year god gold put god prophet togeth sit pretti hmm god place kaaba caravan syria hmm must run thirsti put five men north well mani sheep shall kill seventi give hundr mecca must keep name hospit ten lamb leader bread water poet hakim hous vers prose night put slaughter bread swear thinner water oh open space open space lover poetri abu sufian will patron art abu sofyan invit poet joy kit love kin wine cake abound skill abu sofyan revel song begin abu sofyan invit poet silkworm china ladi pleasur limb ladi see\n",
      "poet joy kit love kin wine cake abound skill abu sofyan revel song begin abu sofyan invit poet silkworm china ladi pleasur limb ladi see ravish eye yes seven length twenti dinar abu sofyan wife fifteen oh gold god kaaba need upkeep man stood look soul carri away must muhammad come stop nephew mayb chang chang forti year old unnatur rich wife could afford best mecca yet choos sit shiver cave unnatur man dare risk anger al uzza keep health manat god prosper allat god famili tribe hubal hubal start caravan predict fate challeng god within earshot god danger unreason rebelli blasphem yes afraid muhammad harm alway sad great fair might see next one abu talib abu talib catch breath zaid muhammad come mount hira yet three day seen khadijah hope might come way home still three day afraid mountain know mean men see world well mountain muhammad read name thi lord creat man sensit drop blood teach man know read still trembl blanket spoken zaid happen nephew mountain alon cave sudden angel came angel said read muhammad repli read angel command read name thi lord creat man sensit drop blood teach man know read know gabriel could dream muhammad come mountain saw gabriel plain shape man stand horizon wherev look upon everi turn head saw gabriel said gabriel muhammad messeng god told wife ali friend abu bakr adopt son care talk tell uncl protect child protect still say god mose spoke burn bush restrain nephew divid citi heart hous divid generat child parent young listen\n",
      "talk tell uncl protect child protect still say god mose spoke burn bush restrain nephew divid citi heart hous divid generat child parent young listen attract young arab obey father children teacher accept man met street yesterday god prophet today dead bone live say creat man also make man return dead say god might leav us give benefit anoth citi tell give author posit key kaaba money money want tell give anyth want muhammad spare put greater burden old man bear childhood arm see hurt refus hurt said put sun right hand moon left would renounc messag god dead may pleas whilst aliv obey father hurt father drunk everi day play dice everi night call high spirit brother children given everyth could seem enough muhammad give give world get father wale father tortur wait hudayfa wait say invent musab new mecca new yet god said noah mose jesus prophet peopl chang turn forgot god said muhammad new jafar brought word god sun overthrown star fall mountain vanish camel big young abandon wild beast herd togeth sea rise soul sort femal infant buri aliv ask crime kill book open sky torn away everi soul know done jafar god gave word dawn come ammar first jaafar ammar kept mother awak night worri sorri father muhammad happen forgiv fault god help us live fell could even help talk listen real god unseen made clay ammar see god kaaba everi day afraid listen peopl hurt listen muhammad mother muhammad generous yes give share pass man without smile spread danger idea\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(new_df.loc[i,'content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1266 entries, 0 to 1265\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       1266 non-null   object\n",
      " 1   content  1266 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 19.9+ KB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "- Chunking has been performed with buffer size of 25 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-2 Send thsee tokens to Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=new_df['content'].to_list(),\n",
    "    ids=new_df['id'].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['0-6', '0-15']],\n",
       " 'distances': [[1.1682987213134766, 1.3359113931655884]],\n",
       " 'metadatas': [[None, None]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['may ask give lion judah know begin friendship begin certain runaway slave escap us kingdom slave go back doubt would return slave us howev free men among rebel rebel disturb arabia inform rebel religion one time anoth religion rebellion bodi slave world beaten dispos jesus christ shepherd soul men sheep arab betray religion father follow lunat call prophet put soul chain without hear good stiff next hang bow prophet muhammad man kneel god muhammad miracl jafar prophet light sky miracl inde true god given prophet sign miracl may recogn miracl muhammad holi quran book book written illiter attribut god think emperor enough mind petti cost god set tongu fire upon head christ apostl could speak mani languag world knew miracl happen time heard enough made poor case suffer persecut mecca muhammad told us go abyssinia land righteous king man wrong call persecut fair punish order prophet send believ book one god sent us heart god protect us talk like draw water mirag belay duti listen friend go year worship wood stone imag manufactur live ignor god earth law heaven law rich neglect poor natur piti man wherebi lift brother fallen describ upset social order inhuman come man god chose believ overcom beg collect speak messeng god muhammad teach us worship one god speak truth love neighbor give chariti even smile chariti protect women misus shelter orphan turn away god wood stone keep still hear blasphemi ancient civil call god wood stone speak ignor idol form worship spirit resid within form agre idolatri alway fulli understood thank',\n",
       "   'end vice versa clear ten year ten year peac need time use time letter muhammad messeng god ruler world call world islam heraclius emperor byzantium kisra emperor persia muqawqi patriarch alexandria god go god great god great god great differ race islam arab superior foreign white man superior black return equal god unless desir neighbour desir faith man goe bed belli full neighbor hungri muslim ink scholar holier blood martyr man read handsom sight god learn read learn teach peopl book jew bibl christian testament must respect book likewis came god must think muhammad man collect firewood one day let said said prophet god go around scratch firewood look mumbl god like man consid men said laid back watch sudden stop stood full height came yes prophet god said even know becom amr come take come ask take wit one god muhammad messeng may god forgiv time fought islam away went sorri came wear jewel worth give poor may offer yes bitterest sword islam god rais sword god ah easi god make die live make lose win two year ago thought beaten sign truce look us charg victori victori heart men abu sofyan come abu sofyan insult like abu sofyan expect courtesi war truce come speak muhammad mosqu muhammad break truce come reaffirm truce speak mecca muhammad turn go muhammad go bedouin broke truce us night dark testifi night dark barra barra citi hudayfa kin aim see must heard mecca leader mecca insult like keep promis respect pledg heard never thought hear abu sofyan ask piti']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue='may ask give lion judah know begin friendship '\n",
    "results = collection.query(\n",
    "    query_texts=[dialogue],\n",
    "    n_results=2\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just return id\n",
    "ids=results['ids'][0]\n",
    "distinct_ids=set()\n",
    "for i in ids:\n",
    "    distinct_ids.add(i.split('-')[0])\n",
    "distinct_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the.message.(1976).eng.1cd\n"
     ]
    }
   ],
   "source": [
    "# Return the name of the series\n",
    "for ind in distinct_ids:\n",
    "    print(df.loc[int(ind),'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import inflect\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "def text_preprocessing(corpus, flag):\n",
    "    # Compiled regular expressions for patterns\n",
    "    pattern1 = re.compile(r'\\d+\\r\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}')\n",
    "    pattern2 = re.compile(r'\\r\\nWatch any video online with Open-SUBTITLES\\r\\nFree Browser extension: osdb.link/ext\\r\\n\\r\\n\\r\\n')\n",
    "    pattern3 = re.compile(r'Please rate this subtitle at www.osdb.link/agwma\\r\\nHelp other users to choose the best subtitles')\n",
    "    pattern4 = re.compile(r'(\\r\\n)+')\n",
    "    pattern5 = re.compile(r'<[/]?\\w+>')\n",
    "    # Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # remove timestamps\n",
    "    corpus = re.sub(pattern1, '', corpus)\n",
    "\n",
    "    # remov header and footer\n",
    "    corpus = re.sub(pattern2, '', corpus)\n",
    "    corpus = re.sub(pattern3, '', corpus)\n",
    "\n",
    "    # remove extra line breaks\n",
    "    corpus = re.sub(pattern4, '\\r\\n', corpus)\n",
    "\n",
    "    # remove html tags\n",
    "    corpus = re.sub(pattern5, '', corpus)\n",
    "\n",
    "    # change  of numbers\n",
    "    #p = inflect.engine()\n",
    "    #corpus = re.sub(r'\\d+', lambda x: p.number_to_words(x.group(0)), corpus)\n",
    "\n",
    "    # remove special characters\n",
    "    corpus = re.sub('[^a-zA-Z]', ' ', corpus)\n",
    "\n",
    "    # convert to lower case\n",
    "    corpus = corpus.lower()\n",
    "\n",
    "    # removal of whitespaces\n",
    "    corpus = ' '.join(corpus.split())\n",
    "\n",
    "    # tokenize\n",
    "    words = word_tokenize(corpus)\n",
    "\n",
    "    # Stemming or Lemmatization\n",
    "    if flag == \"stemming\":\n",
    "        # stemming\n",
    "        stemmer = SnowballStemmer(language='english')\n",
    "        return ' '.join(stemmer.stem(word) for word in words if word not in stop_words)\n",
    "    else:\n",
    "        # lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return ' '.join(lemmatizer.lemmatize(word) for word in words if word not in stop_words)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function where user query returns top 10 relevant searches\n",
    "def getResults(query,flag):\n",
    "    \n",
    "    # Pre process the query\n",
    "    text=text_preprocessing(query, flag)\n",
    "    print(text)\n",
    "    \n",
    "    #query with Chroma DB\n",
    "    results = collection.query(\n",
    "        query_texts=[text],\n",
    "        n_results=30\n",
    "    )\n",
    "    \n",
    "    #get distinct-parent ids\n",
    "    ids=results['ids'][0]\n",
    "    distinct_ids=set()\n",
    "    for i in ids:\n",
    "        distinct_ids.add(i.split('-')[0])\n",
    "    \n",
    "    #query these distinct ids\n",
    "    count=0\n",
    "    results=[]\n",
    "    for ind in distinct_ids:\n",
    "        if count>20: break\n",
    "        results.append(df.loc[int(ind),'name'])\n",
    "        count+=1\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former tv showgirl full physical mental decline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['my.unfamiliar.family.s01.e09.episode.1.9.(2020).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e02.episode.1.2.(2020).eng.1cd',\n",
       " 'my.unfamiliar.family.(2020).eng.1cd',\n",
       " 'my.unfamiliar.family.(2020).eng.1cd',\n",
       " 'that.girl.lay.lay.s02.e01.aint.that.a.glitch.part.one.(2022).eng.1cd',\n",
       " 'westworld.s04.e05.zhuangzi.(2022).eng.1cd',\n",
       " 'that.girl.lay.lay.s02.e01.aint.that.a.glitch.part.one.(2022).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e05.episode.1.5.(2020).eng.1cd',\n",
       " 'price.check.(2012).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e03.episode.1.3.(2020).eng.1cd',\n",
       " 'my.unfamiliar.family.(2020).eng.1cd',\n",
       " 'the.governor.s02.e04.episode.2.4.(1996).eng.1cd',\n",
       " 'survivor.s03.e16.survivor.back.from.africa.(2002).eng.1cd',\n",
       " 'trying.s02.e01.a.nice.boy.(2021).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e12.episode.1.12.(2020).eng.1cd',\n",
       " 'doctor.lawyer.s01.e14.episode.1.14.(2022).eng.1cd',\n",
       " 'the.governor.s02.e06.episode.2.6.(1996).eng.1cd',\n",
       " 'the.great.beauty.(2013).eng.1cd',\n",
       " 'the.governor.s02.e02.episode.2.2.(1996).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e06.episode.1.6.(2020).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e10.episode.1.10.(2020).eng.1cd']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getResults(\"A former TV showgirl, now in full physical and mental decline\",'stemmatization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "- The performance is not that great"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step -2.1 Let's send lemmatized tokens and check the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>decoded_content</th>\n",
       "      <th>pre-processed content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the.message.(1976).eng.1cd</td>\n",
       "      <td>1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch an...</td>\n",
       "      <td>name god gracious merciful muhammad messenger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here.comes.the.grump.s01.e09.joltin.jack.in.bo...</td>\n",
       "      <td>1\\r\\n00:00:29,359 --&gt; 00:00:32,048\\r\\nAh! Ther...</td>\n",
       "      <td>ah princess dawn terry blooney looney soldier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd</td>\n",
       "      <td>1\\r\\n00:00:53,200 --&gt; 00:00:56,030\\r\\n&lt;i&gt;Yumi'...</td>\n",
       "      <td>yumi cell episode extremely polite yumi yumi g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd</td>\n",
       "      <td>1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch an...</td>\n",
       "      <td>yumi cell episode laptop first place mine mine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>broker.(2022).eng.1cd</td>\n",
       "      <td>ï»¿1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch...</td>\n",
       "      <td>going throw away give birth please take care a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                         the.message.(1976).eng.1cd   \n",
       "1  here.comes.the.grump.s01.e09.joltin.jack.in.bo...   \n",
       "2    yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd   \n",
       "3    yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd   \n",
       "4                              broker.(2022).eng.1cd   \n",
       "\n",
       "                                     decoded_content  \\\n",
       "0  1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch an...   \n",
       "1  1\\r\\n00:00:29,359 --> 00:00:32,048\\r\\nAh! Ther...   \n",
       "2  1\\r\\n00:00:53,200 --> 00:00:56,030\\r\\n<i>Yumi'...   \n",
       "3  1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch an...   \n",
       "4  ï»¿1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch...   \n",
       "\n",
       "                               pre-processed content  \n",
       "0  name god gracious merciful muhammad messenger ...  \n",
       "1  ah princess dawn terry blooney looney soldier ...  \n",
       "2  yumi cell episode extremely polite yumi yumi g...  \n",
       "3  yumi cell episode laptop first place mine mine...  \n",
       "4  going throw away give birth please take care a...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_df=df.copy()\n",
    "lem_df['pre-processed content']=df['decoded_content'].apply(lambda x:text_preprocessing(x,'lemmatization'))\n",
    "lem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-0</td>\n",
       "      <td>name god gracious merciful muhammad messenger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-1</td>\n",
       "      <td>abu sofyan revel song begin abu sofyan invite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-2</td>\n",
       "      <td>restrain nephew dividing city heart house divi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-3</td>\n",
       "      <td>muhammad generous yes give share pas man witho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-4</td>\n",
       "      <td>lash face teach mouth lesson whip whip cut whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                            content\n",
       "0  0-0  name god gracious merciful muhammad messenger ...\n",
       "1  0-1  abu sofyan revel song begin abu sofyan invite ...\n",
       "2  0-2  restrain nephew dividing city heart house divi...\n",
       "3  0-3  muhammad generous yes give share pas man witho...\n",
       "4  0-4  lash face teach mouth lesson whip whip cut whi..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create two lists\n",
    "new_id=[]\n",
    "new_content=[]\n",
    "#chunker\n",
    "for i in range(len(lem_df)):\n",
    "    chunker(25,i,lem_df['pre-processed content'][i])\n",
    "\n",
    "new_lem_df=pd.DataFrame({'id':new_id,'content':new_content})\n",
    "new_lem_df\n",
    "new_lem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=chroma_client.get_or_create_collection(name='demo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=new_lem_df['content'].to_list(),\n",
    "    ids=new_lem_df['id'].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['animal.kingdom.s06.e08.revelation.(2022).eng.1cd',\n",
       " 'yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd',\n",
       " 'trying.s02.e03.big.heads.(2021).eng.1cd',\n",
       " 'parallel.world.pharmacy.s01.e03.the.chief.royal.pharmacian.and.the.reincarnated.pharmacologist.(2022).eng.1cd',\n",
       " 'my.unfamiliar.family.(2020).eng.1cd',\n",
       " 'trying.s02.e02.the.sun.on.your.back.(2021).eng.1cd',\n",
       " 'survivor.(2000).eng.1cd',\n",
       " 'the.governor.s01.e02.episode.1.2.(1995).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e07.episode.1.7.(2020).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e05.episode.1.5.(2020).eng.1cd',\n",
       " 'rudrabinar.obhishaap.s02.e05.saat.surer.mejaj.(2022).eng.1cd',\n",
       " 'the.governor.s01.e02.episode.1.2.(1995).eng.1cd',\n",
       " 'animal.kingdom.s06.e08.revelation.(2022).eng.1cd',\n",
       " 'rudrabinar.obhishaap.s02.e01.swaralipir.kut.taan.(2022).eng.1cd',\n",
       " 'reetur.s01.e01.disappointment.and.recruitment.(2019).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e01.episode.1.1.(2020).eng.1cd',\n",
       " 'rudrabinar.obhishaap.s02.e03.anandagarher.akhhyan.(2022).eng.1cd',\n",
       " 'trying.s02.e01.a.nice.boy.(2021).eng.1cd',\n",
       " 'my.unfamiliar.family.s01.e12.episode.1.12.(2020).eng.1cd',\n",
       " 'the.anarchists.s01.e03.currency.(2022).eng.1cd',\n",
       " 'reetur.s01.e06.in.a.land.of.mirrors.(2020).eng.1cd']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a function where user query returns top 10 relevant searches\n",
    "getResults(\"Hello there\",'lemmatization')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>decoded_content</th>\n",
       "      <th>pre-processed content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the.message.(1976).eng.1cd</td>\n",
       "      <td>1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch an...</td>\n",
       "      <td>name god gracious merci muhammad messeng god h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>here.comes.the.grump.s01.e09.joltin.jack.in.bo...</td>\n",
       "      <td>1\\r\\n00:00:29,359 --&gt; 00:00:32,048\\r\\nAh! Ther...</td>\n",
       "      <td>ah princess dawn terri blooney looney soldier ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd</td>\n",
       "      <td>1\\r\\n00:00:53,200 --&gt; 00:00:56,030\\r\\n&lt;i&gt;Yumi'...</td>\n",
       "      <td>yumi cell episod extrem polit yumi yumi get ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd</td>\n",
       "      <td>1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch an...</td>\n",
       "      <td>yumi cell episod laptop first place mine mine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>broker.(2022).eng.1cd</td>\n",
       "      <td>ï»¿1\\r\\n00:00:06,000 --&gt; 00:00:12,074\\r\\nWatch...</td>\n",
       "      <td>go throw away give birth pleas take care anyth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                         the.message.(1976).eng.1cd   \n",
       "1  here.comes.the.grump.s01.e09.joltin.jack.in.bo...   \n",
       "2    yumis.cells.s02.e13.episode.2.13.(2022).eng.1cd   \n",
       "3    yumis.cells.s02.e14.episode.2.14.(2022).eng.1cd   \n",
       "4                              broker.(2022).eng.1cd   \n",
       "\n",
       "                                     decoded_content  \\\n",
       "0  1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch an...   \n",
       "1  1\\r\\n00:00:29,359 --> 00:00:32,048\\r\\nAh! Ther...   \n",
       "2  1\\r\\n00:00:53,200 --> 00:00:56,030\\r\\n<i>Yumi'...   \n",
       "3  1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch an...   \n",
       "4  ï»¿1\\r\\n00:00:06,000 --> 00:00:12,074\\r\\nWatch...   \n",
       "\n",
       "                               pre-processed content  \n",
       "0  name god gracious merci muhammad messeng god h...  \n",
       "1  ah princess dawn terri blooney looney soldier ...  \n",
       "2  yumi cell episod extrem polit yumi yumi get ma...  \n",
       "3  yumi cell episod laptop first place mine mine ...  \n",
       "4  go throw away give birth pleas take care anyth...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
